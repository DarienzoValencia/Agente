ğŸ§  CesantÃ­as-POC
Prueba de Concepto â€” Agente Inteligente para Consultas de CesantÃ­as y Empresa

Este proyecto construye una prueba de concepto (POC), donde un usuario puede realizar preguntas que serÃ¡n interpretadas por un agente inteligente basado en un modelo de lenguaje (LLM).
El agente decide dinÃ¡micamente entre dos acciones posibles:

Responder con conocimiento general de la empresa (a travÃ©s de un sistema de bÃºsqueda semÃ¡ntica basado en embeddings y FAISS).

Consultar informaciÃ³n de cesantÃ­as causadas en una base local (archivo Excel) y devolver el resultado exacto.

ğŸš€ Objetivo

Desarrollar un agente conversacional con capacidad de:

Comprender el contexto y la intenciÃ³n del usuario.

Determinar si la pregunta requiere conocimiento institucional o datos de cesant[ias.

Responder usando herramientas especÃ­ficas (tools) para cada caso.

Mantener contexto y razonamiento controlado con LangGraph.

ğŸ§© Arquitectura General

Componentes principales:

LangGraph Agent: Define la lÃ³gica de conversaciÃ³n y la toma de decisiones del LLM.

Tools (funciones externas):

validardoc: consulta informaciÃ³n de cesantÃ­as en un archivo Excel.

vector_search: realiza bÃºsqueda semÃ¡ntica con embeddings y FAISS para preguntas sobre la empresa.

Modelo LLM: Configurado en models_llm.py, responsable del razonamiento y la generaciÃ³n de respuestas.

Prompts personalizados: Definidos en prompts.py para guiar el comportamiento del agente segÃºn el contexto corporativo.

Memoria y Control de Estado: Manejados con MemorySaver de LangGraph.

```
ğŸ—‚ï¸ Estructura del Proyecto
CesantÃ­as-POC/
â”‚
â”œâ”€â”€ app.py                  # Punto de entrada principal del agente
â”œâ”€â”€ models_llm.py           # ConfiguraciÃ³n del modelo LLM y bindings
â”œâ”€â”€ prompts.py              # Prompts usados por el agente
â”œâ”€â”€ tools.py                # Tools (funciones) usadas por el agente
â”œâ”€â”€ vector_search.py        # Proceso de retrieval y bÃºsqueda semÃ¡ntica
â”œâ”€â”€ teoria_.pdf             # Documento teÃ³rico con sustento conceptual
â”œâ”€â”€ requirements.txt        # Dependencias del proyecto
â””â”€â”€ README.md               # Este archivo
```

âš™ï¸ InstalaciÃ³n y EjecuciÃ³n Local
1ï¸âƒ£ Clonar el repositorio
git clone https://github.com/tu_usuario/Cesantias-POC.git
cd Cesantias-POC

2ï¸âƒ£ Crear entorno virtual
python -m venv .venv
source .venv/Scripts/activate  # En Windows

3ï¸âƒ£ Instalar dependencias
pip install -r requirements.txt

4ï¸âƒ£ Ejecutar la aplicaciÃ³n
python app.py


Luego puedes escribir preguntas directamente en la consola, por ejemplo:

> Â¿CuÃ¡nto tengo ahorrado en mis cesantÃ­as?
> Â¿QuÃ© beneficios ofrece la empresa?

ğŸ§® Funcionamiento del Agente

El flujo del agente sigue esta lÃ³gica:

El usuario realiza una pregunta.

El modelo LLM, desplegado mediante LangGraph, analiza la intenciÃ³n.

Si la pregunta contiene datos sobre cesantÃ­as â†’ usa la tool validardoc.

Si se relaciona con informaciÃ³n de la empresa â†’ usa la tool vector_search.

Retorna la respuesta final estructurada en JSON, junto con su proceso interno de decisiÃ³n.

ğŸ§  Modelos y Embeddings

Embeddings: Se deja espresado un modelo de open-ai

Vector Store: FAISS (faiss-cpu) para almacenar y buscar los 10 resultados mÃ¡s similares por similitud del coseno.

LLM: Modelo configurable, compatible con OpenAI o alternativas locales (por ejemplo, gpt-4o-mini, Llama-3, etc.).

ğŸ“„ Entregables

app.py: flujo principal del agente.

ğŸ§° TecnologÃ­as Utilizadas
Tipo	TecnologÃ­a
Lenguaje	Python 3.11
Framework IA	LangGraph / LangChain
Almacenamiento vectorial	FAISS
Formato de Respuestas	JSON estructurado
